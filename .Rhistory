setwd(C:\\Users\\nurma\\OneDrive\\MyEd\\01 Sem 1\\03 ext stat pr\\gitrep\\Team12)
setwd(C:/Users/nurma/OneDrive/MyEd/01 Sem 1/03 ext stat pr/gitrep/Team12)
setwd("C:/Users/nurma/OneDrive/MyEd/01 Sem 1/03 ext stat pr/gitrep/Team12")
# PROJECT 1 - EXTENDED STATISTICAL PROGRAMMING =================================
# Group 12
# Aseel Alghamdi : S2901228
# Fenanda Dwitha Kurniasari : S2744048
# Nurmawiya : S2822251
# Aseel : Tabulating common words, matrix M preparation, femael.predict
# Fenanda : Removing stage direction, creating next.word & femael.predict
# Nurmawiya : Removing full uppercase & number, creating split_punct & next.word
# Notes :
# Femael.predict function (stands for Fenanda, Nurma, Aseel) allows you to input
# keywords and display the output resulted in next.word (predicted token(s))
# into predicted word(s)
a <- scan("shakespeare.txt", what="character", skip=83, nlines=196043-83,
fileEncoding="UTF-8")
# Removing stage directions
loc_1 <- grep("[", a, fixed=TRUE) #locating open square bracket [
length_a <- length(a)
all_loc <- NULL
for (i in loc_1){
#locating stage directions within next 100 words with close square bracket ]
loc_2 <- grep("]", a[i:min((i+100), length_a)], fixed=TRUE)
#locating full stop (.) for unmatched brackets
loc_3 <- grep(".", a[i:min((i+100),length_a)], fixed=TRUE)
#locating words to exclude
if(length(loc_2) > 0){
loc_exc <- c(i:(loc_2[1] + (i) - (1)))
} else{loc_exc <- c(i:(loc_3[1] + (i) - (1)))}
ifelse (i == loc_1[1],
all_loc <- loc_exc,
all_loc <- append(all_loc, loc_exc))
}
#Removing stage directions from a
a <- a[-(all_loc)]
#Removing full-uppercase letter exclude I and A, and removing numbers from a
upnum_loc <- which(toupper(a)==a & !(a %in% c("I", "A")) | grepl("[0-9]", a))
a <- a[-(upnum_loc)]
#Removing underscore, dash, parentheses and asterisk from a
a <- gsub("[*()_-]", "", a)
#Splitting punctuation marks from every word and lowercase
punct <- c(",", ".", ";", "!", ":", "?")
split_punct <- function (x){
for (i in punct) {
x <- gsub(paste0('[', i, ']'), paste0("#", i), x)
}
x <- tolower(unlist(strsplit(x, "[#]", perl = TRUE)))
}
a <- split_punct(a)
# Tabulating common words
b <- unique(a)
freq <- tabulate(match(a,b))
b <- which(rank(-freq) <= 1000) #average ties method, rank 1 = most common word
#final dataset of b contains indices of top ~1000 words from the unique words
# Preparing M and M1 matrices
b_word <- a[b]
n <- length(a)
mlag <- 4
mrow <- n - mlag
mcol <- mlag + 1
M1 <- match(a, b_word) #M1 = token
M <- matrix(NA, mrow, mcol)
for (i in 0:4) {
M[,i+1] <- M1[(i+1) : (mrow+i)]
}
# Predicting the next word tokens
next.word <- function(key, M, M1, w = rep(1, ncol(M) - 1)) {
ii <- c()
match.row <- c()
k.match <- match(key, b_word)
loc.key <- which(is.finite(k.match))
key.n   <- k.match[loc.key]
# If key > 4, use only the last mlag elements
if (length(key.n) > mlag) key.n <- tail(key.n, mlag)
if (length(key.n) != 0) {
mc <- mlag - (length(key.n) - 1)  # start column
# find matching row
ii <- colSums(!(t(M[, mc:mlag, drop = FALSE]) == key.n))
}
match.row <- which(ii == 0 & is.finite(ii))
# Condition 1 - Token key(s) exactly match with j-th row
if (length(match.row) == 1) {
chosen <- match.row
nxt <- M[chosen, mlag + 1]
nxt.word <- b_word[nxt]
# Condition 2 - Token key(s) match with n j-th row
# Calculate weight each row and sample a row based on weighted probability
} else if (length(match.row) > 1) {
w <- rep(1,length(match.row))
chosen <- sample(match.row, 1, prob = w)
nxt <- M[chosen, mlag + 1]
nxt.word <- b_word[nxt]
# Condition 3 - Token key(s) doesn't match with any row in M
# Calculate weight in M1 and sample a "word" based on weighted probability
} else {
nxt <- sample(M1, 1, prob = rep(1, length(M1)))
nxt.word <- a[nxt]
}
# If nxt.word = NA, then sample again M1 and exlude NA based on weighted prob
if (is.na(nxt.word)) {
nxt <- sample(M1[!is.na(M1)], 1, prob = rep(1, sum(!is.na(M1))))
nxt.word <- a[nxt]
}
return(nxt.word)
}
# Keyword(s) input and return the predicted results
femael.predict <- function(M, M1) {
set.seed(17)
repeat {
key <- readline(prompt = "Please input the key: ")
if (length(key) > 0 &&
is.na(suppressWarnings(as.numeric(key))) &&
key!="") {
# Generate words until we reach full stop
while (length(grep (".", key, fixed = TRUE)) == 0) {
key <- unlist(strsplit(key, " "))
key <- split_punct(key)
nxt.w <- next.word(key, M, M1)
key <- c(key, nxt.w)  # append predicted word
}
cat("The result is:\n")
#removing spaces before punctuation
res <- gsub("  ([[:punct:]])", "\\1", paste(key, collapse = " "))
res <- gsub(" ([[:punct:]])", "\\1", paste(res, collapse = " "))
print(res)
break #Exit loop if condition is satisfied
} else {
cat("Invalid input. Please input another key.\n")
}
}
}
# Simulation
femael.predict(M,M1)
# 1) Create n people assigned to corresponding household where maximum size is 5
n <- 1000 #population size
hmax <- 5 #maximum household size
#creating n vector of which the number refers to household
#and the occurences refers to size of corresponding household
set.seed(3)
h <- rep(1:n, times=sample(1:hmax, n, replace=TRUE))[1:n]
h
# 2) Contact network
#nc = average number of contacts per person
#beta = sociability parameter
get.net <- function (beta, nc=15, h) {
n <- length(beta)
beta_bar <- mean(beta)
links <- vector("list", n)
for (i in 1:(n-1)) {
for (j in (i+1):n) {
if (h[i] != h[j]) { # exclude household members
p_link <- nc * beta[i] * beta[j] / (beta_bar^2 * (n - 1))
if (runif(1) < p_link) {
links[[i]] <- c(links[[i]], j)
links[[j]] <- c(links[[j]], i)
}
}
}
}
return(links)
}
# 2) Contact network
#nc = average number of contacts per person
#beta = sociability parameter
get.net <- function (beta, nc=15, h) {
n <- length(beta)
beta_bar <- mean(beta)
links <- vector("list", n)
for (i in 1:(n-1)) {
for (j in (i+1):n) {
if (h[i] != h[j]) { # exclude household members
p_link <- nc * beta[i] * beta[j] / (beta_bar^2 * (n - 1))
if (runif(1) < p_link) {
links[[i]] <- c(links[[i]], j)
links[[j]] <- c(links[[j]], i)
}
}
}
}
return(links)
}
# 2) Contact network
#nc = average number of contacts per person
#beta = sociability parameter
get.net <- function (beta, nc=15, h) {
n <- length(beta)
beta_bar <- mean(beta)
links <- vector("list", n)
for (i in 1:(n-1)) {
for (j in (i+1):n) {
if (h[i] != h[j]) { # exclude household members
p_link <- nc * beta[i] * beta[j] / (beta_bar^2 * (n - 1))
if (runif(1) < p_link) {
links[[i]] <- c(links[[i]], j)
links[[j]] <- c(links[[j]], i)
}
}
}
}
return(links)
}
# 2) Contact network
#nc = average number of contacts per person
#beta = sociability parameter
get.net <- function (beta, nc=15, h) {
n <- length(beta)
beta_bar <- mean(beta)
links <- vector("list", n)
for (i in 1:(n-1)) {
for (j in (i+1):n) {
if (h[i] != h[j]) { # exclude household members
p_link <- nc * beta[i] * beta[j] / (beta_bar^2 * (n - 1))
if (runif(1) < p_link) {
links[[i]] <- c(links[[i]], j)
links[[j]] <- c(links[[j]], i)
}
}
}
}
return(links)
}
#function to create links for each person
n <- length(beta)
beta_bar <- mean(beta)
links <- vector("list", n)
n
beta <- runif(n, 0, 1) #setting beta vector ~ U(0, 1)
beta
# 1) Create n people assigned to corresponding household where maximum size is 5
n <- 1000 #population size
beta <- runif(n, 0, 1) #setting beta vector ~ U(0, 1)
beta
n <- length(beta)
n
state <- rep("S", n)
#function to create links for each person
n <- length(beta)
state
N
N
n
beta_bar <- mean(beta)
beta_bar
links <- vector("list", n)
links
for (i in 1:(n-1)) { #loop over person 1 until 999
for (j in (i+1):n) { #loop over person 2 until 1000
if (h[i] != h[j]) { #exclude household members
p_link <- nc * beta[i] * beta[j] / (beta_bar^2 * (n - 1))
if (runif(1) < p_link) {
links[[i]] <- c(links[[i]], j)
links[[j]] <- c(links[[j]], i)
}
}
}
}
links <- vector("list", n)
for (i in 1:(n-1)) { #loop over person 1 until 999
for (j in (i+1):n) { #loop over person 2 until 1000
if (h[i] != h[j]) {
#if ith and jth person are not belong to the same household
#then calculate each plink
p_link <- nc * beta[i] * beta[j] / (beta_bar^2 * (n - 1))
if (runif(1) < p_link) {
links[[i]] <- c(links[[i]], j)
links[[j]] <- c(links[[j]], i)
}
}
}
}
nc=15
links <- vector("list", n)
for (i in 1:(n-1)) { #loop over person 1 until 999
for (j in (i+1):n) { #loop over person 2 until 1000
if (h[i] != h[j]) {
#if ith and jth person are not belong to the same household
#then calculate each plink
p_link <- nc * beta[i] * beta[j] / (beta_bar^2 * (n - 1))
if (runif(1) < p_link) {
links[[i]] <- c(links[[i]], j)
links[[j]] <- c(links[[j]], i)
}
}
}
}
return(links)
links <- vector("list", n)
for (i in 1)) { #loop over person 1 until 999
links <- vector("list", n)
for (i in 1) { #loop over person 1 until 999
for (j in (i+1):n) { #loop over person 2 until 1000
if (h[i] != h[j]) {
#if ith and jth person are not belong to the same household
#then calculate each plink
p_link <- nc * beta[i] * beta[j] / (beta_bar^2 * (n - 1))
if (runif(1) < p_link) {
links[[i]] <- c(links[[i]], j)
links[[j]] <- c(links[[j]], i)
}
}
}
}
links
head(links)
links <- vector("list", n)
for (i in 1:(n-1)) { #loop over person 1 until 999
for (j in (i+1):n) { #loop over person 2 until 1000
if (h[i] != h[j]) {
#if ith and jth person are not belong to the same household
#then calculate each plink
p_link <- nc * beta[i] * beta[j] / (beta_bar^2 * (n - 1))
if (runif(1) < p_link) {
links[[i]] <- c(links[[i]], j)
links[[j]] <- c(links[[j]], i)
}
}
}
}
return(links)
links
h
ave_check <- mean(sapply(alink, length))
alink <- get.net(beta, nc=15, h)
ave_check <- mean(sapply(alink, length))
ave_check
runif(1)
runif(1)
p_link
links[[i]] <- c(links[[i]], j)
links[[i]]
i
links[[j]] <- c(links[[j]], i)
links[[j]]
links
j
res <- matrix(0, nrow = nt, ncol = 4)
nt=100
res <- matrix(0, nrow = nt, ncol = 4)
res
colnames(res) <- c("S", "E", "I", "R")
es
res
